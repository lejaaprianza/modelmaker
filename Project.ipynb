{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHNO58ma1mQPS/izdgLVHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lejaaprianza/modelmaker/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuT1bif034wQ",
        "outputId": "2bd75e20-70c3-4969-d348-8533b4ecee11"
      },
      "source": [
        "!pip install -q tflite-model-maker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 593kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 30.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.3MB 44.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 51.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 35.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 849kB 28.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 10.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 38.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 61.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 58.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 45.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 48.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 38.2MB 1.2MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArjHB1ma4Fy4",
        "outputId": "3904b0d4-5e37-4367-ac11-edd1f41694f9"
      },
      "source": [
        "path = os.path.join('sample_data','join')\n",
        "print(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data/join\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGcE-8b943Sd",
        "outputId": "c2a16ccc-640c-458f-ea96-3ed31233b0d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxXEHEQB45qo"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDe6PYas46e2",
        "outputId": "ab99efd3-10d7-4b6e-ffeb-1ce13ce7ab94"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Makanan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Makanan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p8YSLrq63O6"
      },
      "source": [
        "image_path = 'Datates'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7nuZQW948z0",
        "outputId": "081c5553-0de7-4620-b969-4c417a6b117a"
      },
      "source": [
        "data = DataLoader.from_folder(image_path)\n",
        "train_data, test_data = data.split(0.9)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Load image with size: 934, num_label: 17, labels: Ayam Goreng, Bika Ambon, Bubur, Gado-Gado, Gudeg, Gulai Ikan, Kue Lumpur, Nasi Goreng, Pempek, Rawon, Rendang, Rujak Cingur, Sate Ayam, Soto Ayam, Soto Banjar, Tahu Telur, Tekwan.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Load image with size: 934, num_label: 17, labels: Ayam Goreng, Bika Ambon, Bubur, Gado-Gado, Gudeg, Gulai Ikan, Kue Lumpur, Nasi Goreng, Pempek, Rawon, Rendang, Rujak Cingur, Sate Ayam, Soto Ayam, Soto Banjar, Tahu Telur, Tekwan.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaMG9-lB5DZN",
        "outputId": "10198ec6-b692-47e5-f092-3c48e578be7a"
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        " \n",
        "def resizePhoto(filePath,formatImg):\n",
        "  os.mkdir('/content/drive/MyDrive/Colab Notebooks/Makanan/Datates/'+filePath)\n",
        "    #Retriving all image names and it's path with .jpg extension from given directory path in imageNames list\n",
        "  imageNames = glob.glob(r\"/content/drive/MyDrive/Colab Notebooks/Makanan/DatasetBaru/Dataset/\"+filePath+\"/*.\"+formatImg)\n",
        "\n",
        "  #Defining width and height of image\n",
        "  new_width  = 224\n",
        "  new_height = 224\n",
        "\n",
        "  #Count variable to show the progress of image resized\n",
        "  count=0\n",
        "\n",
        "  #Creating for loop to take one image from imageNames list and resize\n",
        "  for i in imageNames:\n",
        "    #opening image for editing\n",
        "    img = Image.open(i)\n",
        "    #using resize() to resize image\n",
        "    img = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
        "    #save() to save image at given path and count is the name of image eg. first image name will be 0.jpg\n",
        "    img.save(r\"/content/drive/MyDrive/Colab Notebooks/Makanan/Datates/\"+filePath+\"/\"+str(count)+\".\"+formatImg) \n",
        "    #incrementing count value\n",
        "    count+=1\n",
        "    #showing image resize progress\n",
        "    print(\"Images Resized \" +str(count)+\"/\"+str(len(imageNames)),end='\\r')\n",
        "resizePhoto('Ayam Goreng','jpg')\n",
        "resizePhoto('Bika Ambon','jpg')\n",
        "resizePhoto('Bubur','jpg')\n",
        "resizePhoto('Gado-Gado','jpg')\n",
        "resizePhoto('Gudeg','jpg')\n",
        "resizePhoto('Gulai Ikan','jpg')\n",
        "resizePhoto('Kue Lumpur','jpg')\n",
        "resizePhoto('Nasi Goreng','jpg')\n",
        "resizePhoto('Pempek','jpg')\n",
        "resizePhoto('Rawon','jpg')\n",
        "resizePhoto('Rendang','jpg')\n",
        "resizePhoto('Rujak Cingur','jpg')\n",
        "resizePhoto('Sate Ayam','jpg')\n",
        "resizePhoto('Soto Ayam','jpg')\n",
        "resizePhoto('Soto Banjar','jpg')\n",
        "resizePhoto('Tahu Telur','jpg')\n",
        "resizePhoto('Tekwan','jpg')\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipraEWks7R8o",
        "outputId": "f8ae18b7-8be1-4fde-8066-e3780418603b"
      },
      "source": [
        "model = image_classifier.create(train_data, epochs=20, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hub_keras_layer_v1v2_5 (HubK (None, 1280)              3413024   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 17)                21777     \n",
            "=================================================================\n",
            "Total params: 3,434,801\n",
            "Trainable params: 21,777\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "84/84 [==============================] - 28s 309ms/step - loss: 1.1260 - accuracy: 0.8524\n",
            "Epoch 2/20\n",
            "84/84 [==============================] - 26s 309ms/step - loss: 0.6455 - accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "84/84 [==============================] - 26s 308ms/step - loss: 0.6320 - accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "84/84 [==============================] - 26s 309ms/step - loss: 0.6258 - accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "84/84 [==============================] - 26s 307ms/step - loss: 0.6204 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "84/84 [==============================] - 26s 307ms/step - loss: 0.6176 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "84/84 [==============================] - 26s 309ms/step - loss: 0.6147 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "84/84 [==============================] - 26s 308ms/step - loss: 0.6128 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "84/84 [==============================] - 26s 308ms/step - loss: 0.6107 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "84/84 [==============================] - 26s 306ms/step - loss: 0.6098 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "84/84 [==============================] - 26s 307ms/step - loss: 0.6086 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "84/84 [==============================] - 26s 309ms/step - loss: 0.6078 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "84/84 [==============================] - 26s 309ms/step - loss: 0.6057 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "84/84 [==============================] - 26s 309ms/step - loss: 0.6049 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "84/84 [==============================] - 26s 310ms/step - loss: 0.6046 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "84/84 [==============================] - 26s 312ms/step - loss: 0.6027 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "84/84 [==============================] - 26s 310ms/step - loss: 0.6036 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "13/84 [===>..........................] - ETA: 22s - loss: 0.6011 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xLXu9HI-jHr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}